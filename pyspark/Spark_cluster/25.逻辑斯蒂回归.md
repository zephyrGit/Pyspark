
分类模型里最常用的就是Logistic regression逻辑回归模型了，逻辑回归他是一宗广义的线性模型，但是需要注意虽然名字里面有‘回归’二字，但是他是一种分类莫模型。逻辑回归有多个变种，最常用的是用于二分类，当然对于多分类也是适用的。对于分类实际上他会分成k-1个二分类任务。在pyspark.ml中逻辑回归莫i选哪个有两种实现算法，分别是mini-batch gradient desent小批量的梯度下降算法，还有就是L-BFGS拟牛顿法。官方推荐使用L-BFGS拟牛顿法，原因是它具有更快的收敛速度  
通过损失函数可以求出权重对应的梯度，从而沿着梯度的负方向更新权重参数直至收敛。模型训练好只有，对于输入的特征向量X，需要用到下面的逻辑函数 
$$f(z) = \frac{1}{1+e^-z}$$
其中z=W*X + b;如果f(z) > 0.5判断为正，f(z) < 0.5判断为负  
**Sigmoid函数及其导数**  
$$h_\theta = g(\theta^T x) = \frac{1}{1+e^-\theta x}$$
-->
$$g(z) = \frac{1}{1+e^-z}$$
-->
$$g`(x) = \frac{1}{1+e^-x} = \frac{e^-x}{(1+e^-x)^2}$$
-->
$$=\frac{1}{1+e^-x}\cdot\frac{e^-x}{1+e^x} = \frac{1}{1+e^-z} \cdot (1 - \frac{1}{1+e^-x)}$$
-->
$$g(x)\cdot(1-g(x))$$

**Logistic损失函数**  
![image.png](attachment:image.png)
接下来使用二分类逻辑回归算法。regParam用于指定正则化强度，elasticNetParam用于指定L1和L2正则化影响的权重，通过maxIter指定算法迭代的次数为10  

~~~python

from pyspark.ml.classification import LogisticRegression
training = spark.read.format('libsvm').load('D:/data/mllib/sample_libsvm_data.txt')
lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)
lrModel = lr.fit(training)
print('Coefficients:' + str(lrModel.coefficients))
print('Intercept:' + str(lrModel.intercept))
>>> 
Coefficients:(692,[244,263,272,300,301,328,350,351,378,379,405,406,407,428,433,434,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.35398352419e-05,-9.10273850559e-05,-0.000194674305469,-0.000203006424735,-3.14761833149e-05,-6.84297760266e-05,1.58836268982e-05,1.40234970914e-05,0.00035432047525,0.000114432728982,0.000100167123837,0.00060141093038,0.000284024817912,-0.000115410847365,0.000385996886313,0.000635019557424,-0.000115064123846,-0.00015271865865,0.000280493380899,0.000607011747119,-0.000200845966325,-0.000142107557929,0.000273901034116,0.00027730456245,-9.83802702727e-05,-0.000380852244352,-0.000253151980086,0.000277477147708,-0.000244361976392,-0.00153947446876,-0.000230733284113])
Intercept:0.22456315961250325


mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8,family='multinomial')
mlrModel = mlr.fit(training)
print('Multinomial coefficients:' + str(mlrModel.coefficientMatrix))
print('Multinomial intercepts:' + str(mlrModel.interceptVector))
>>> 
Multinomial coefficients:2 X 692 CSRMatrix
(0,244) 0.0
(0,263) 0.0001
(0,272) 0.0001
(0,300) 0.0001
(0,350) -0.0
(0,351) -0.0
(0,378) -0.0
(0,379) -0.0
(0,405) -0.0
(0,406) -0.0006
(0,407) -0.0001
(0,428) 0.0001
(0,433) -0.0
(0,434) -0.0007
(0,455) 0.0001
(0,456) 0.0001
..
..
Multinomial intercepts:[-0.120658794459,0.120658794459]
~~~

在算法中可以使用精度和召回率来衡量算法的好坏程度，基于这两个指标衍生出了F1坐标，它是精度和召回率两个指标的调和平均数。还有一种度量性能的指标是ROC曲线，ROC曲线的横坐标为false positive rate(FPR),纵坐标为true positive rate(TPR),越靠近左上角性能越好


在LogisticRegression中提供了LogisticRegressionTrainingSummary用于对算法执行过程中性能的度量。可以通过LogisticRegressionTrainingSummary对上上的fMeasureByThrdshold获取由不同的阀值而计算出来的F1调和平均数 

~~~python

from pyspark.ml.classification import LogisticRegression

trainingSummary = lrModel.summary
objectiveHistory = trainingSummary.objectiveHistory
print('objectiveHistory:')
for objective in objectiveHistory:
    print(objective)

trainingSummary.roc.show()
print('areaUnderROC:' + str(trainingSummary.areaUnderROC))

fMeasure = trainingSummary.fMeasureByThreshold
maxFMeasure = fMeasure.groupBy().max('F-Measure').select(
    'max(F-Measure)').head()
bestThreshold = fMeasure.where(
    fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']).select(
        'threshold').head()['threshold']
lr.setThreshold(bestThreshold)
>>> 
objectiveHistory:
0.6833149135741672
0.6662875751473734
0.6217068546034618
0.6127265245887887
0.6060347986802873
0.6031750687571562
0.5969621534836274
0.5940743031983118
0.5906089243339022
0.5894724576491042
0.5882187775729587
+---+--------------------+
|FPR|                 TPR|
+---+--------------------+
|0.0|                 0.0|
|0.0|0.017543859649122806|
|0.0| 0.03508771929824561|
|0.0| 0.05263157894736842|
|0.0| 0.07017543859649122|
|0.0| 0.08771929824561403|
|0.0| 0.10526315789473684|
|0.0| 0.12280701754385964|
|0.0| 0.14035087719298245|
|0.0| 0.15789473684210525|
|0.0| 0.17543859649122806|
|0.0| 0.19298245614035087|
|0.0| 0.21052631578947367|
|0.0| 0.22807017543859648|
|0.0| 0.24561403508771928|
|0.0|  0.2631578947368421|
|0.0|  0.2807017543859649|
|0.0|  0.2982456140350877|
|0.0|  0.3157894736842105|
|0.0|  0.3333333333333333|
+---+--------------------+
only showing top 20 rows

areaUnderROC:1.0
LogisticRegression_40aaabb4b9d924d079cf

fMeasure = trainingSummary.fMeasureByThreshold
fMeasure.show()
>>> 
+------------------+--------------------+
|         threshold|           F-Measure|
+------------------+--------------------+
|0.7845860015371142|0.034482758620689655|
|0.7843193344168922| 0.06779661016949151|
|0.7842976092510131|                 0.1|
|0.7842531051133191| 0.13114754098360656|
|0.7835792429453297| 0.16129032258064516|
|0.7835223585829078|  0.1904761904761905|
| 0.783284563364102|             0.21875|
|0.7832449070254992| 0.24615384615384614|
|0.7830630257264691|  0.2727272727272727|
|0.7830068256743365| 0.29850746268656714|
|0.7822341175907138|  0.3235294117647059|
| 0.782111826902122| 0.34782608695652173|
| 0.781220790993743|  0.3714285714285714|
|0.7802700864854707|  0.3943661971830986|
|0.7789683616171501|  0.4166666666666667|
|0.7789606764592472|  0.4383561643835616|
|0.7788060694625324| 0.45945945945945943|
|0.7783754276111222|  0.4799999999999999|
|0.7771658291080574|                 0.5|
|0.7769914303593917|  0.5194805194805194|
+------------------+--------------------+
only showing top 20 rows
~~~

最后可以由fMeasureByThreshold选择出当F-Measure最大时对应的threshold阀值。使用模型上的setThreshold方法把效果最好的阀值设置上去  

逻辑回归除了能对二分类进行分类之外，还可以用于多分类任务。输入的是多酚类的概率，使用的是Softmax分类函数：  
![image.png](attachment:image.png)
最终最小化负的对数似然加上有阿尔法调节的L1和L2权重参数正则化项，由L1和L2组成弹性的惩罚项，避免过拟合 ![image.png](attachment:image.png)

~~~python

from pyspark.ml.classification import LogisticRegression

training = spark.read.format('libsvm').load(
    '/data/mllib/sample_multiclass_classification_data.txt')
lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)
lrModel = lr.fit(training)
print('Coefficients:' + str(lrModel.coefficientMatrix))
print('Intercept:' + str(lrModel.interceptVector))
>>> 
Coefficients:3 X 4 CSRMatrix
(0,3) 0.3176
(1,2) -0.7804
(1,3) -0.377
Intercept:[0.0516523165983,-0.123912249909,0.0722599333102]

trainingSummary = lrModel.summary
objectiveHistory = trainingSummary.objectiveHistory
print('objectiveHistory:')
for objective in objectiveHistory:
    print(objective)
>>> 
objectiveHistory:
1.098612288668108
1.087602085441699
1.0341156572156232
1.0289859520256006
1.0300389657358995
1.0239965158223991
1.0236097451839508
1.0231082121970012
1.023022220302788
1.0230018151780262
1.0229963739557606

print('False positive rate by label:')
for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):
    print('label %d: %s '% (i,rate))
>>> 
False positive rate by label:
label 0: 0.22 
label 1: 0.05 
label 2: 0.0 

print('True positive rate by label:')
for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):
    print('label %d: %s' % (i, rate))
>>> 
True positive rate by label:
label 0: 1.0
label 1: 1.0
label 2: 0.46

print('Precision by label:')
for i, prec in enumerate(trainingSummary.precisionByLabel):
    print('label %d: %s' % (i, prec))
>>> 
Precision by label:
label 0: 0.6944444444444444
label 1: 0.9090909090909091
label 2: 1.0

print('Recall by label:')
for i, rec in enumerate(trainingSummary.recallByLabel):
    print('label %d : %s' % (i, rec))
>>> 
Recall by label:
label 0 : 1.0
label 1 : 1.0
label 2 : 0.46

print('F-measure by label:')
for i, f in enumerate(trainingSummary.fMeasureByLabel()):
    print('label %d: %s' % (i, f))
>>> 
F-measure by label:
label 0: 0.819672131147541
label 1: 0.9523809523809523
label 2: 0.6301369863013699

accuracy = trainingSummary.accuracy
falsePositiveRate = trainingSummary.weightedFalsePositiveRate
truePositiveRate = trainingSummary.weightedTruePositiveRate
fMeasure = trainingSummary.weightedFMeasure()
precision = trainingSummary.weightedPrecision
recall = trainingSummary.weightedRecall

print(
    'Accuracy: %s\nFPR: %s\nTPR: %s\nF-measure: %s\nPrecision: %s\nRecall: %s'
    % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision,
       recall))
>>> 
Accuracy: 0.82
FPR: 0.09
TPR: 0.82
F-measure: 0.8007300232766211
Precision: 0.8678451178451179
Recall: 0.82
~~~
