
1. 朴素贝叶斯分类器是使用概率模型来完成分类的模型，其理论支撑位朴素贝叶斯理论，其假设两两特征之间完全独立。这简化了计算，但是在很多需要特征相关性的地方如自然语言处理领域，上下文是相关联的，基于朴素贝叶斯理论去实现分类效果不理想，这需要借助RNN中的LSTM和GAU模型来做  

2. 朴素贝叶斯理论  
朴素： 基于贝叶斯定理  
根据贝叶斯定理，对于一个分类问题，给定样本特征x，样本属于y的概率是  
$$p(y|x) = \frac {p(y|x)p(y}{p(x)}$$
在这里，x是一个特征向量，将设x维度为M。因为朴素的假设，即特征条件独立，根据全概率公式展开，公式（1）可以表达为  
$$p(y = c_k|x) = \frac {\prod_{i=1}^M p(x^i|y = c_k) p(y=c_k)}{\Sigma_k p(y=c_k) \prod_{i=1}^M P(x^i|y = c_k)}$$ 
这里，只要分别估计出，特征xi在每一类的条件概率就可以了。类别y的先验概率可以通过训练集算  
-----------

**基于朴素贝叶斯文本分类构建的过程**  
1. 构造数据，产生中为导入外部的数据及标签  
2. 由标签计算每个类别在文档及出现的概率p(yi)
3. 记录文档的个数
4. 由所有的文档生成词典【[tempsetadd(word) for doc in trainset for word in doc]】，并计算出词典的长度
5. 由训练集计算出**tfidf**
6. 按分类累积向量空间的每维值P(x|y)
7. 计算test*p(x|y)取最大值对应的label为预测的类别  

3. 使用朴素贝叶斯算法来进行二分类  

~~~python

from pyspark.sql import SparkSession
from pyspark.ml.classification import NaiveBayes
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

spark = SparkSession.builder.master('local').appName(
    'NativeBayes').getOrCreate()
    data = spark.read.format('libsvm').load('/data/mllib/sample_libsvm_data.txt')
splits = data.randomSplit([0.6,0.4],1234)
train = splits[0]
test = splits[1]

nb = NaiveBayes(smoothing=1.0, modelType='multinomial') 
model = nb.fit(train)
predictions = model.transform(test)
predictions.show()

evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',metricName='accuracy')
accuracy = evaluator.evaluate(predictions)
print('Test set accuracy = ' + str(accuracy))
>>> 
+-----+--------------------+--------------------+-----------+----------+
|label|            features|       rawPrediction|probability|prediction|
+-----+--------------------+--------------------+-----------+----------+
|  0.0|(692,[95,96,97,12...|[-174115.98587057...|  [1.0,0.0]|       0.0|
|  0.0|(692,[98,99,100,1...|[-178402.52307196...|  [1.0,0.0]|       0.0|
|  0.0|(692,[100,101,102...|[-100905.88974016...|  [1.0,0.0]|       0.0|
|  0.0|(692,[123,124,125...|[-244784.29791241...|  [1.0,0.0]|       0.0|
|  0.0|(692,[123,124,125...|[-196900.88506109...|  [1.0,0.0]|       0.0|
|  0.0|(692,[124,125,126...|[-238164.45338794...|  [1.0,0.0]|       0.0|
|  0.0|(692,[124,125,126...|[-184206.87833381...|  [1.0,0.0]|       0.0|
|  0.0|(692,[127,128,129...|[-214174.52863813...|  [1.0,0.0]|       0.0|
|  0.0|(692,[127,128,129...|[-182844.62193963...|  [1.0,0.0]|       0.0|
|  0.0|(692,[128,129,130...|[-246557.10990301...|  [1.0,0.0]|       0.0|
|  0.0|(692,[152,153,154...|[-208282.08496711...|  [1.0,0.0]|       0.0|
|  0.0|(692,[152,153,154...|[-243457.69885665...|  [1.0,0.0]|       0.0|
|  0.0|(692,[153,154,155...|[-260933.50931276...|  [1.0,0.0]|       0.0|
|  0.0|(692,[154,155,156...|[-220274.72552901...|  [1.0,0.0]|       0.0|
|  0.0|(692,[181,182,183...|[-154830.07125175...|  [1.0,0.0]|       0.0|
|  1.0|(692,[99,100,101,...|[-145978.24563975...|  [0.0,1.0]|       1.0|
|  1.0|(692,[100,101,102...|[-147916.32657832...|  [0.0,1.0]|       1.0|
|  1.0|(692,[123,124,125...|[-139663.27471685...|  [0.0,1.0]|       1.0|
|  1.0|(692,[124,125,126...|[-129013.44238751...|  [0.0,1.0]|       1.0|
|  1.0|(692,[125,126,127...|[-81829.799906049...|  [0.0,1.0]|       1.0|
+-----+--------------------+--------------------+-----------+----------+
only showing top 20 rows

Test set accuracy = 1.0
~~~
预测结果很好，都预测正确
