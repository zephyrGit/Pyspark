
1. 机器学习需要借助向量计算和矩阵计算，例如再scikit—learn中的各种机器学习算法，可以使用numpy中的向量和矩阵进行并行计算。


2. 在mlib数据类型中有本地向量和矩阵，本地向量和矩阵存放在单节点上，除了本地向量还支持分布式和矩阵向量，分布式矩阵和向量存储在RDD中。底层的线性代数的运算是由Breeze库提供支持，Breeze是一个机器学习和数值计算的库。在监督的学习中，pyspark使用的数据类型“labeled point” 


3.  Local vector本地向量，本地向量是一个以整数并且0为起始的索引的double类型的数组，存储在单节点上，在mllib中支持两种类型的本地向量，一种是密集的dense，另外一种是稀疏的sparse。密集向量实际上是bouble类型的数组，而sparse稀疏向量由两个对应的数组组成，一个数组存放索引，另一个数组存放值  
dese向量：[1.1,2.2,3.3,4.56]
sparse向量：(10,[1,9],[1.9,2.8])，10表示是稀疏向量的大小，1和9是1.9和2.8在稀疏向量种的索引


4. mllib可以把numpy数组和python本地的数组看做是密集向量。例如：  
data1 = np.array([1,2,3,4,5.])  
data2 = [2.3,4.5,5.9,9.0,3.14]  
使用numpy和python数组创建的都是属于密集向量

5. 稀疏向量可以由mllib种的SparseVector提供的方法创建，也可以使用Scipy种对应的csc_matrix方法来创建。csc_matrix是Scipy种对应的用于创建稀疏矩阵的方法，csc的全名Compassed Sparse Column，即压缩的稀疏列

~~~python
import numpy as np
import scipy.sparse as sp
from pyspark.mllib.linalg import Vectors

sv = Vectors.sparse(3, [0, 2], [1.0, 3.0])
row = np.array([0, 2])
col = np.array([0, 2])
data = [99, 88.]
sp.csc_matrix((data, (row, col)), shape=(3, 3)).toarray()
>>> 
array([[99.,  0.,  0.],
       [ 0.,  0.,  0.],
       [ 0.,  0., 88.]])
sv
>>>  SparseVector(3, {0: 1.0, 2: 3.0})
~~~

6. labeled point是一个本地向量，可以是密集也可以是稀疏，他的特殊之处是它有一个额外的标签，在mllib种label point用于有监督的机器学习。标签类型是一个double类型，因此说可以使用label point类型的向量来做分类，可以用来做回归算法。在milib种带的标签向量由LabeledPoint来表示，创建一个LabeledPoint  

~~~python
from pyspark.mllib.linalg import SparseVector
from pyspark.mllib.regression import LabeledPoint

pos = LabeledPoint(1.0, [1.0, 0.0, 3.0])
neg = LabeledPoint(0.0, SparseVector(3, [0, 2], [1.0, 3.0]))
pos
>>> 
LabeledPoint(1.0, [1.0,0.0,3.0])
neg
>>> 
LabeledPoint(0.0, (3,[0,2],[1.0,3.0]))
~~~

7. Sparse数据实际上在机器学习种事很常见的，例如词向量，购物车数据等。在mllib种支持读取LIBSVM格式的数据，他是一个文本格式，代表的是带有标签的且稀疏的特征向量，其格式如下：  
label index1:value index2:value2 ...

~~~python
from pyspark.mllib.util import MLUtils

result = MLUtils.loadLibSVMFile(sc, './datas/')
result
>>> 
result.top(1)
>>>
~~~

8. 矩阵，分为本地矩阵和分布式矩阵。本地矩阵有整数类型的行和列标签，还有double类型的数值组成。本地矩阵也有密集和稀疏两种类型，对于dense密集矩阵，其所有数据存储在一个单独的double类型的数组中。而稀疏矩阵是按照CSC格式以列为顺序存储的。mllib中对于矩阵的基类是Matrix类，基于这个类实现了DenseMatrix和SparseMatrix。在构建本地矩阵的时候，推荐使用Matrixcex方法去创建。<font color=#FF0000 >注意：本地矩阵是以列为顺序进行存储的</font>

~~~python
from pyspark.mllib.linalg import Matrix, Matrices

m1 = Matrices.dense(2, 3, [9, 3, 4, 5, 7, 1])
m1
>>> DenseMatrix(2, 3, [9.0, 3.0, 4.0, 5.0, 7.0, 1.0], False)
m1.toArray()
>>>
array([[9., 4., 7.],
       [3., 5., 1.]])
m2 = Matrices.sparse(3, 2, [0, 1, 3], [0, 2, 1], [9, 6, 8])
m2
>>> SparseMatrix(3, 2, [0, 1, 3], [0, 2, 1], [9.0, 6.0, 8.0], False)
m2.toArray()
>>> 
array([[9., 0.],
       [0., 8.],
       [0., 6.]])
~~~
**注意Matrices的spares方法的参数，分别为numRows，numCols，colPtrs，rowIndices，values**

9. 除了本地矩阵之外，还有一种类型的矩阵，分布式矩阵，现在mllib中分布式矩阵有四种实现类  
RowMatrix：  
它是一个面向行的分布式矩阵，但是没有行索引，其对应于RDD数据集中的行，其中每行是一个本地的向量。正是由于每一行都是一个本地的向量，因此列的数量被限制在int能表示的范围之内，在实际中特征的个数大多数情况下是小于这个范围的，因此能够被完整的表示  
RowMatrix可以使用包含多个数组的RDD来创建

~~~python
from pyspark.sql import SparkSession
from pyspark.mllib.linalg.distributed import RowMatrix

spark = SparkSession.builder.master('local').appName('ml').getOrCreate()
sc = spark.sparkContext

rows = sc.parallelize([[1,2,3], [4,5,6], [7,8,9],[10,11,12]], 3)
mat = RowMatrix(rows)
dir(mat)
>>> 
['__class__','__delattr__','__dict__','__dir__','__doc__','__eq__','__format__','__ge__','__getattribute__','__gt__','__hash__','__init__','__init_subclass__','__le__','__lt__','__module__','__ne__','__new__','__reduce__','__reduce_ex__','__repr__','__setattr__','__sizeof__','__str__','__subclasshook__','__weakref__','_java_matrix_wrapper','columnSimilarities','computeColumnSummaryStatistics','computeCovariance','computeGramianMatrix','computePrincipalComponents','computeSVD','multiply','numCols','numRows','rows','tallSkinnyQR']

m = mat.numRows()
n = mat.numCols()
rowsRDD = mat.rows
type(rowsRDD)
>>> pyspark.rdd.RDD
~~~

IndexedRowMatrix:  
这种Matrix和上面的RowMatrix很类似，区别的地方是增加了一个long类的行索引。IndexedRowMatrix可以丢掉index索引而转换成RowMatrix。创建IndexedRowMatrix有两种方法，一种是使用IndexedRow对象，另外一种使用二维tuple，tuple的第一个元素为index行标签，第二个元素为values值是一个local向量

~~~python
from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix

indexedRows = sc.parallelize([
    IndexedRow(0, [1, 2, 3]),
    IndexedRow(1, [4, 5, 6]),
    IndexedRow(2, [7, 8, 9]),
    IndexedRow(3, [10, 11, 12])
], 3)
indexedRows = sc.parallelize([(0, [1, 2, 3]), 
                              (1, [4, 5, 6]), 
                              (2, [7, 8, 9]),
                              (3, [10, 11, 12])])
mat = IndexedRowMatrix(indexedRows)
m = mat.numRows()
n = mat.numCols()
rowsRDD = mat.rows
rowMat = mat.toRowMatrix()
rowsRDD
>>>  PythonRDD[21] at RDD at PythonRDD.scala:52
rowMat
>>>  <pyspark.mllib.linalg.distributed.RowMatrix at 0x1d877483a90>
~~~
CoordinateMatrix: 基于坐标的矩阵，这种矩阵其背后也是RDD支撑，RDD中的每条数据格式为(i,j,value)，i表示行坐标，j表示列坐标，value表示对应的值。其使用场景是矩阵维度很高并且非常稀疏的场景，例如词向量等。CoorDinageMatrix可以转换为RowMatrix，通过调用toRowMatrix是(long,long,float)类型的包装，CoordinateMatrix可以转换为RowMatrix，通过调用toRowMatrix来进行转换。也可以通过toIndexedRowMatrix方法转换为IndexedRowMatrix对象

~~~python
entries = sc.parallelize([
    MatrixEntry(0, 0, 1.2),
    MatrixEntry(1, 0, 2.1),
    MatrixEntry(6, 1, 3.7)
], 2)
entries = sc.parallelize([(0, 0, 1.2), (1, 0, 2.1), (2, 1, 3.7)], 2)
mat = CoordinateMatrix(entries)
n = mat.numCols() # 2
m = mat.numRows() # 3 
entriesRDD = mat.entries
entriesRDD.collect()
>>>  [MatrixEntry(0, 0, 1.2), MatrixEntry(1, 0, 2.1), MatrixEntry(2, 1, 3.7)]
rowMat = mat.toRowMatrix()
indexedRowMat = mat.toIndexedRowMatrix()
blockMat = mat.toBlockMatrix()
rowMat
>>>  <pyspark.mllib.linalg.distributed.RowMatrix at 0x184fb81aba8>
indexedRowMat
>>>  <pyspark.mllib.linalg.distributed.IndexedRowMatrix at 0x184fb81a9e8>
blockMat
>>>  <pyspark.mllib.linalg.distributed.BlockMatrix at 0x184fb873c18>
~~~
BlockMatrix：是分块矩阵，其背后仍然是RDD作为支撑，RDD中的元素为MatrixBlocks类型，MatrixBlock是一个二元tuple类型，((Int, Int), Matrix),其中(Int, Int)表示的是block的索引信息，而Matrix为对应的分块矩阵。BlockMatrix支持和其它的BolckMatrix做add和maltiply乘积操作，BlockMatrix也具有辅助方法，用于检测设置是否合理。构造BolckMatrix要传入rdd和rowPerBlock，colPerBlock参数  

~~~python
from pyspark.mllib.linalg import Matrices
from pyspark.mllib.linalg.distributed import BlockMatrix

blocks = sc.parallelize(
    [((0, 0), Matrices.dense(3, 2, [1, 2, 3, 4, 5, 6])),
     ((0, 1), Matrices.dense(3, 2, [7, 8, 9, 10, 11, 12]))], 2)
# 每个分块矩阵的行数是3， 列数是2
mat = BlockMatrix(blocks, 3, 2)
m = mat.numCols() # 2
n = mat.numRows() # 6
blocksRDD = mat.blocks
localMat = mat.toLocalMatrix()
blocksRDD.collect()
>>> 
[((0, 0), DenseMatrix(3, 2, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0], 0)),
 ((0, 1), DenseMatrix(3, 2, [7.0, 8.0, 9.0, 10.0, 11.0, 12.0], 0))]
# 将分块矩阵转换为带索引的行矩阵
indexedRowMat = mat.toIndexedRowMatrix()
# 分块矩阵转换为基于坐标的矩阵
coordinateMat = mat.toIndexedRowMatrix()
~~~
