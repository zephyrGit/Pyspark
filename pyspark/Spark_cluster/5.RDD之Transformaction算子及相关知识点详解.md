
- 1.cache()使用默认的缓存级别MEMORY_ONLY将数据进行持久化  
持久化级别有如下取值：
~~~python
Data and other attributes defined here:
DISK_ONLY = StorageLevel(True, False, False, False, 1)
DISK_ONLY_2 = StorageLevel(True, False, False, False, 2)
MEMORY_AND_DISK = StorageLevel(True, True, False, False, 1)
MEMORY_AND_DISK_2 = StorageLevel(True, True, False, False, 2)
MEMORY_AND_DISK_SER = StorageLevel(True, True, False, False, 1)
MEMORY_AND_DISK_SER_2 = StorageLevel(True, True, False, False, 2)
MEMORY_ONLY = StorageLevel(False, True, False, False, 1)
MEMORY_ONLY_2 = StorageLevel(False, True, False, False, 2)
MEMORY_ONLY_SER = StorageLevel(False, True, False, False, 1)
MEMORY_ONLY_SER_2 = StorageLevel(False, True, False, False, 2)
OFF_HEAP = StorageLevel(True, True, True, False, 1)
~~~

可以调用rdd上的getStorageLevel获取当前rdd对应的持久化级别
~~~python
from pyspark import SparkContext, SparkConf
import numpy as np

conf = SparkConf()
conf.setMaster("local").setAppName("cache")
sc = SparkContext(conf=conf)

rdd = sc.parallelize(np.arange(10),3)
rdd.getStorageLevel()
>>> StorageLevel(False, False, False, False, 1)
rdd.cache()
>>> PythonRDD[2] at RDD at PythonRDD.scala:52
rdd.getStorageLevel()
>>> StorageLevel(False, True, False, False, 1)
~~~

- 2.persist(storageLevel=StorageLevel(False, True, False, False,1))这个方法可以使用关键字参数storageLevel指定缓存级别。默认的缓存级别是MEMORY_ONLY,设置之后可以调用rdd上的is_cached竖井确认是否已经将RDD数据持久化。持久化选项如“1”所示  
~~~python
import numpy as np
rdd1 = sc.parallelize(np.arange(10),3)
rdd1.persist(storageLevel=StorageLevel(False, True, False, False, 2))
>>> ParallelCollectionRDD[4] at parallelize at PythonRDD.scala:194
rdd1.getStorageLevel()
>>> StorageLevel(False, True, False, False, 2)
rdd1.is_cached
>>> True
~~~
unpersist()与persist相反，该方法取消RDD的持久化，并从memoryManager中删除对应的持久化的block信息
~~~python
rdd1.unpersist()
>>> ParallelCollectionRDD[4] at parallelize at PythonRDD.scala:194
rdd1.is_cached
>>> False
~~~

- 3.cartesian(other)当前的rdd和‘other’rdd原始的笛卡尔乘积，返回的是两个RDD元素两两组合的二元tuple
~~~python
rdd1 = sc.parallelize(np.arange(10),3)
rdd2 = sc.parallelize(np.arange(10),2)
rdd3 = rdd1.cartesian(rdd2)
rdd3.getNumPartitions()
>>> 6
rdd3.collect()
>>> 
~~~

- 4.checkpoint()设置检查点，该操作将气短该RDD的所有父依赖，调用该方法之前，首先要调用SparkContext.setCheckpointDir()方法设置检查点的存储在HDFS上的位置，强烈建议将该RDD的存储级别设置为内存级别，否则的话由于依赖链端粒，如果再次使用到该RDD的话，将会从磁盘中的检查点目录中再次读取数据，会耗费IO及CPU资源。在一些重要的计算节点设置checkpoint是一个好的习惯，这样可以有效的进行异常错误的快速恢复
~~~python
sc.setCheckpointDir('./datas/checkpoint/')
rdd3.checkpoint()
rdd3.collect()
>>> hdfs dfs -cat /data/checkpoint/..../part-00000
~~~

- 5.coalesce(numPartitions, shuffle=False)调用该方法对RDD进行重分区，分区数回影响作业的并行度，因此会视作业的具体情况设置合理的bingxingdu。这个方法有一个关键字参数shuffle，默认为False，因它的重分区行为不会涉及到shuffle操作，效率较高，若设置为True，效果和repartition方法类似，效率较低
~~~python
rdd = sc.parallelize(np.arange(10),6)
rdd.getNumPartitions()
>>> 6
rdd1 = rdd.coalesce(2)
rdd1.getNumPartitions()
>>> 2
~~~
repartition(numPartitions)该方法也是用于对RDD进行重分区，其内部使用的是Shuffle重新分区数据，如果要减少RDD中分区的数量，推荐使用coalesce方法
~~~python
rdd2 = rdd.repartition(3)
rdd2.getNumPartitions()
>>> 3
~~~

partitiongBy(numPartitons, partitionFunc=<function portable_hash>)使用给定分区方法将RDD分为numPartitions个。partitionFunc为可选参数，若未指定，其效果如同repartititon，默认使用基于shuffle的机制进行重分区数据
    
~~~python
pairs = sc.parallelize([1, 2, 3, 4, 2, 4, 1]).map(lambda x: (x, x))
sets = pairs.partitionBy(2).glom().collect()
sets
>>>
[[(2, 2), (4, 4), (2, 2), (4, 4)], [(1, 1), (3, 3), (1, 1)]]

paris.collect()
>>> [1, 4, 9, 16, 4, 16, 1]
a = pairs.partitionBy(2, partitionFunc=lambda x: x%2==0).glom().collect()
a
>>> [[(1, 1), (3, 3), (1, 1)], [(2, 2), (4, 4), (2, 2), (4, 4)]]
~~~
