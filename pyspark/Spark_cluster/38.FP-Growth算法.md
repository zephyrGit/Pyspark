
1. 构建FP树  


事物ID | 事务中的元素项 
 -| - 
 001|r,z,h,j,p
 002|z,y,x,w,v,u,t,s
 003|z
 004|r,x,n,o,s
 005|y,r,x,z,q,t,p
 006|y,z,x,e,q,s,t,m
 
 
 为构建FP树，需要对原始数据集扫描两遍  
 
 
 第一遍对所有元素项的出现次数进行计数，统计各个元素项的出现频率，去掉不满足最小支持度的元素项。L={'s':3,'r':3,'t':3,'y':3,'x'x:4,'z':5}  
 
 
 FP-growth算法还需要一个称为头指针表来指定元素项的第一树节点并记录各个元素项的出现次数。这样每个元素项构成一条单链表，可以快速访问FP树种一个给定元素项的所有元素  

- 第二遍扫描数据集用来构建FP树。在构建时，读入每个项集并将其添加到一条已经存在的路径中。如果该路径不存在，则创建一条新路径，在将每条事务加到树之前，需要对每个集合进行排序。排序基于元素项的绝对出现频率由高到低来进行，并过滤出不在L中的非频繁项  
- 过滤及重排后的事务如下：  

事务ID | 事务中的元素项 | 过及重排序后的事务
- | - | -
001 | r,z,h,j,p | z, r
002 | z,y,x,w,v,u,t,s | z,x,y,s,t
003 | z | z,
004 | r,x,n,o,s | x,s,r
005 | y,r,x,z,q,t,p | z,x,y,r,t
006 | y,z,x,e,q,s,t,m | z,x,y,s,t

- 在对事务记录过滤和排序之后，就可以构建FP树了。从空集开始，将过滤和重排序后的频繁项集一次添加到树中。如果树中已存在现有元素，则增加现有元素的值；如果现有元素不存在，则向树添加一个分支。 

使用FP-Growth算法，通过minSupport设置最小的支持度，minConfidence设置最小置信度。对于这两个概念，可参照如下的理解：  

支持度（support）  
支持度：{X,Y}同时出现的概率，例如{牛奶， 啤酒}同时出现的概率  
support = 同时购买{x，y}的人数/总人数  
{牛奶， 啤酒}的支持度 = 800 / 10000 = 0.008
{牛奶， 面包}的支持度 = 100 / 10000 = 0.01
注意：{牛奶， 啤酒}的支持度等于{啤酒， 牛奶}的支持度，支持度没有先后顺序之分  
置信度（confidence）  
置信度：购买X的人，同时购买Y的概率，例如：购买牛奶的人，同时购买啤酒的概率，而这个概率就是购买牛奶时购买啤酒的置信度  
confidence（X -> Y）= 同时购买{X,Y}的人数 / 购买X的人数  
confidence（Y -> X）= 同时购买{X,Y}的人数 / 购买Y的人数  
（牛奶 -> 啤酒）的置信度 = 800 / 1000 = 0.8
（啤酒 -> 牛奶）的置信度 = 800 / 2000 = 0.4

使用pyspark构建FPGrowth  

~~~python

from pyspark.sql import SparkSession
from pyspark.ml.fpm import FPGrowth

spark = SparkSession.builder.master('local').appName('fpgrowth').getOrCreate()
df = spark.createDataFrame([(0, [1, 2, 5]), (1, [1, 2, 3, 5]), (2, [1, 2])],
                           ['id', 'items'])

fpGrowth = FPGrowth(itemsCol='items', minSupport=0.5, minConfidence=0.6)
model = fpGrowth.fit(df)
model.freqItemsets.show()
>>>  
+---------+----+
|    items|freq|
+---------+----+
|      [5]|   2|
|   [5, 2]|   2|
|[5, 2, 1]|   2|
|   [5, 1]|   2|
|      [2]|   3|
|   [2, 1]|   3|
|      [1]|   3|
+---------+----+

model.associationRules.show()
>>>  
+----------+----------+------------------+
|antecedent|consequent|        confidence|
+----------+----------+------------------+
|    [5, 2]|       [1]|               1.0|
|    [5, 1]|       [2]|               1.0|
|       [5]|       [2]|               1.0|
|       [5]|       [1]|               1.0|
|       [2]|       [5]|0.6666666666666666|
|       [2]|       [1]|               1.0|
|       [1]|       [5]|0.6666666666666666|
|       [1]|       [2]|               1.0|
|    [2, 1]|       [5]|0.6666666666666666|
+----------+----------+------------------+

model.transform(df).show()
>>>   
+---+------------+----------+
| id|       items|prediction|
+---+------------+----------+
|  0|   [1, 2, 5]|        []|
|  1|[1, 2, 3, 5]|        []|
|  2|      [1, 2]|       [5]|
+---+------------+----------+
~~~
